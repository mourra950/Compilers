{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7954bd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from enum import Enum\n",
    "import re\n",
    "import pandas\n",
    "import pandastable as pt\n",
    "from nltk.tree import *\n",
    "class Token_type(Enum): # listing all tokens type\n",
    "    Begin=1\n",
    "    End=2\n",
    "    Do=3 \n",
    "    Else=4\n",
    "    EndIf=5 \n",
    "    If=6\n",
    "    Integer=7\n",
    "    Dot=8\n",
    "    Semicolon=9\n",
    "    EqualOp=10 \n",
    "    LessThanOp=11\n",
    "    GreaterThanOp=12\n",
    "    NotEqualOp=13\n",
    "    PlusOp=14 \n",
    "    MinusOp=15\n",
    "    MultiplyOp=16\n",
    "    DivideOp=17\n",
    "    Identifier=18\n",
    "    Constant=19\n",
    "    Program=20\n",
    "    Procedure=21\n",
    "    Parameters=22\n",
    "    Declare=23\n",
    "    Error=24\n",
    "# class token to hold string and token type\n",
    "class token:\n",
    "    def __init__(self, lex, token_type):\n",
    "        self.lex = lex\n",
    "        self.token_type = token_type\n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            'Lex': self.lex,\n",
    "            'token_type': self.token_type\n",
    "        }\n",
    "            \n",
    "#Reserved word Dictionary\n",
    "ReservedWords={\"IF\":Token_type.If,\n",
    "               \"PROGRAM\":Token_type.Program,\n",
    "               \"PROCEDURE\":Token_type.Procedure,\n",
    "               \"Parameters\":Token_type.Parameters,\n",
    "               \"Declare\":Token_type.Declare,\n",
    "             \"END\":Token_type.End,\n",
    "               \"BEGIN\":Token_type.Begin,\n",
    "               \"DO\":Token_type.Do,\n",
    "               \"ElSE\":Token_type.Else,\n",
    "               \"ENDIF\":Token_type.EndIf,\n",
    "               \"INTEGER\":Token_type.Integer\n",
    "               }\n",
    "Operators={\".\":Token_type.Dot,\n",
    "          \";\":Token_type.Semicolon,\n",
    "          \"=\":Token_type.EqualOp,\n",
    "          \"+\":Token_type.PlusOp,\n",
    "           \"-\":Token_type.MinusOp,\n",
    "           \"*\":Token_type.MultiplyOp,\n",
    "           \"/\":Token_type.DivideOp\n",
    "          }\n",
    "Tokens=[]\n",
    "errors=[]\n",
    "\n",
    "def find_token(text):\n",
    "    lexems=text.split()\n",
    "    for le in  lexems:\n",
    "        if(le in ReservedWords ):\n",
    "            new_token=token(le,ReservedWords[le])\n",
    "            Tokens.append(new_token)\n",
    "        elif(le in Operators):\n",
    "            new_token=token(le,Operators[le])\n",
    "            Tokens.append(new_token)\n",
    "        elif (re.match(\"^\\d+(\\.[0-9]*)?$\",le)):\n",
    "            new_token=token(le,Token_type.Constant)\n",
    "            Tokens.append(new_token)    \n",
    "        elif (re.match(\"^([a-zA-Z][a-zA-Z0-9]*)$\",le)):\n",
    "            new_token=token(le,Token_type.Identifier)\n",
    "            Tokens.append(new_token)    \n",
    "        else : \n",
    "            new_token=token(le,Token_type.Error)\n",
    "            errors.append(\"Lexical error  \"+ le)\n",
    "           \n",
    "    \n",
    "\n",
    "\n",
    "def Parse():\n",
    "    j=0\n",
    "    Children=[]\n",
    "    Header_dict=Header(j)\n",
    "    Children.append(Header_dict[\"node\"])\n",
    "#     Block_dict = Block(Header_dict[\"index\"])\n",
    "#     Children.append(block_dict[\"node\"])\n",
    "    dic_output=Match(Token_type.Dot,j)\n",
    "    Children.append(dic_output[\"node\"])\n",
    "    Node=Tree('Program',Children)\n",
    "    \n",
    "    return Node\n",
    "def Header(j):\n",
    "    Children =[]\n",
    "    output = dict()\n",
    "    \n",
    "    out1 = Match(Token_type.Program, j)\n",
    "    Children.append(out1[\"node\"])\n",
    "    \n",
    "    out2 = Match(Token_type.Identifier, out1[\"index\"])\n",
    "    Children.append(out2[\"node\"])\n",
    "    \n",
    "    out3 = Match(Token_type.Semicolon, out2[\"index\"])\n",
    "    Children.append(out3[\"node\"])\n",
    "\n",
    "    Node = Tree(\"Header\", Children)\n",
    "    output[\"node\"] = Node\n",
    "    output[\"index\"] = out3[\"index\"]\n",
    "    return output\n",
    "\n",
    "\n",
    "def Match(a,j):\n",
    "    output=dict()\n",
    "    if(j<len(Tokens)):\n",
    "        Temp=Tokens[j].to_dict()\n",
    "        if(Temp['token_type']==a):\n",
    "            j+=1\n",
    "            output[\"node\"]=[Temp['Lex']]\n",
    "            output[\"index\"]=j\n",
    "            return output\n",
    "        else:\n",
    "            output[\"node\"]=[\"error\"]\n",
    "            output[\"index\"]=j+1\n",
    "            errors.append(\"Syntax error : \")\n",
    "            return output\n",
    "    else:\n",
    "        output[\"node\"]=[\"error\"]\n",
    "        output[\"index\"]=j+1\n",
    "        return output\n",
    "#GUI\n",
    "root= tk.Tk()\n",
    "\n",
    "canvas1 = tk.Canvas(root, width=400, height=300, relief='raised')\n",
    "canvas1.pack()\n",
    "\n",
    "label1 = tk.Label(root, text='Scanner Phase')\n",
    "label1.config(font=('helvetica', 14))\n",
    "canvas1.create_window(200, 25, window=label1)\n",
    "\n",
    "label2 = tk.Label(root, text='Source code:')\n",
    "label2.config(font=('helvetica', 10))\n",
    "canvas1.create_window(200, 100, window=label2)\n",
    "\n",
    "entry1 = tk.Entry(root) \n",
    "canvas1.create_window(200, 140, window=entry1)\n",
    "\n",
    "def Scan():\n",
    "    x1 = entry1.get()\n",
    "    find_token(x1)\n",
    "    df=pandas.DataFrame.from_records([t.to_dict() for t in Tokens])\n",
    "    #print(df)\n",
    "      \n",
    "    #to display token stream as table\n",
    "    dTDa1 = tk.Toplevel()\n",
    "    dTDa1.title('Token Stream')\n",
    "    dTDaPT = pt.Table(dTDa1, dataframe=df, showtoolbar=True, showstatusbar=True)\n",
    "    dTDaPT.show()\n",
    "    # start Parsing\n",
    "    Node=Parse()\n",
    "     \n",
    "    \n",
    "    # to display errorlist\n",
    "    df1=pandas.DataFrame(errors)\n",
    "    dTDa2 = tk.Toplevel()\n",
    "    dTDa2.title('Error List')\n",
    "    dTDaPT2 = pt.Table(dTDa2, dataframe=df1, showtoolbar=True, showstatusbar=True)\n",
    "    dTDaPT2.show()\n",
    "    Node.draw()\n",
    "    #clear your list\n",
    "    \n",
    "    #label3 = tk.Label(root, text='Lexem ' + x1 + ' is:', font=('helvetica', 10))\n",
    "    #canvas1.create_window(200, 210, window=label3)\n",
    "    \n",
    "    #label4 = tk.Label(root, text=\"Token_type\"+x1, font=('helvetica', 10, 'bold'))\n",
    "    #canvas1.create_window(200, 230, window=label4)\n",
    "    \n",
    "    \n",
    "button1 = tk.Button(text='Scan', command=Scan, bg='brown', fg='white', font=('helvetica', 9, 'bold'))\n",
    "canvas1.create_window(200, 180, window=button1)\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b0c4c5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4679e9f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fde760",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53520700",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
